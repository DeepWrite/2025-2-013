---
title: 013-23 최지호 (과제-09)
layout: home
nav_order: 23
parent: 과제-09 기말과제 최종본
permalink: /asmt-09/013-23
---

# (최종본) 과제-09 기말과제 013-23 최지호 

# 제목: AI의 과학은 인간의 과학을 뛰어넘는가?

## 서론

이성적 활동은 오랜 기간 인간의 전유물로 여겨져 왔으며, 따라서 논쟁의 여지 없이 학문의 주체는 인간이었다. 인간을 제외하고는 이성을 가진 주체를 찾아볼 수 없었기 때문에 이 사실이 쟁점이 되지 않음은 자연스러웠다. 그러나 2020년대에 AI의 시대가 도래함에 따라, 이 당연한 듯했던 사실은 더 이상 당연시되지 않는다. AI는 마치 인간이 오랜 시간 고민하며 써내려간 듯한 긴 글을 수 초 내에 써낼 수 있으며, 인간만이 풀 수 있다고 여겨지던, 혹은 어떤 인간도 풀 수 없을 것이라 여겨지던 문제들을 분야에 구애받지 않고 모든 학문 영역에서 풀어내고 있다. 이성적 활동이 인간만의 전유물임은 더 이상 자명한 명제가 아니며, 이 사실이 더욱 치명적으로 다가오는 분야는 **과학**이다. 가설 설정과 실험·관찰을 통하여 명제를 정립해나가는 경험과학이든, 전제된 공리계 내에서 명제를 연역해나가는 형식과학이든, AI는 모든 과학 분야에서 날마다 새로운 돌파구를 발견해내고 있으며, 이에 따라 현재 과학 이론의 축적 속도는 역사상 그 어느 때보다도 빠르다. 이는 자연스레 과학자·과학철학자들 사이에 AI가 도출한 과학적 사실을 진정 '과학'으로 인정할 수 있느냐는 논쟁을 불러일으켰다. 추론 과정이 불분명한 AI의 발견을 과학으로 인정할 수 있을까? 과학의 주체로 인간 이외의 무언가를 인정할 수 있을까? 그리고 우리는 AI의 발견을 신뢰할 수 있을까? 학계에서 수많은 질문이 제기되고 그에 따라 다양한 쟁점에 대한 논의가 진행되고 있으나, 본고에서는 AI의 발견이 과학으로서 정당화될 수 있는지 여부와 AI의 발견의 신뢰 가능성에 초점을 맞추어 논의를 전개하고자 한다. 이는 AI의 발견의 과학적 지위를 공고히 하여 후속 논의의 전제를 마련하기 위함과 동시에 학계에서 AI를 통한 증명의 자동화 혹은 연구 보조 도구로서의 활용이 급속히 증가함에 따라 그 신뢰 가능성과 그에 대한 엄밀한 검증의 필요성이 대두되고 있기 때문이다.

AI의 과학적 발견에 대하여 학계는 크게 두 가지 의견으로 입장을 달리한다. AI의 추론 과정에의 부족한 설명력에 초점을 맞추어 그것을 과학으로 인정할 수 없다는 입장과, AI의 월등한 예측 가능성과 정확도에 초점을 맞추어 그것을 과학으로 충분히 인정할 수 있다는 실용주의적 입장이 대표적이다. 본고에서는 AI의 발견이 **검증 가능성**을 충족하면 과학적 명제로서 정당화될 수 있으며, 거기서 그치지 않고 그 경우 AI의 과학은 인간의 과학보다 **더 신뢰 가능하다**는 점을 주장한다. 이를 위하여 먼저 과학의 본질은 **검증 가능성**임을 검토하며, 검증 가능성의 필요 조건은 명제의 이해 가능성임을 논증한다. 이어 AI의 추론 과정의 불분명함이 그 발견의 이해 불가능성을 의미하지는 않는다는 점을 살펴보며, 이해 가능한 발견이라면 그에 대한 검증 가능성의 판단과 검증을 통하여 AI의 발견이 **과학으로서 정당화될 수 있다**는 점을 논증한다. 다음으로 인간의 과학적 연구는 인지적 편향, 재현성 위기(reproductibility crisis) 등 본질적인 문제를 안고 있음을 살펴본 뒤, AI의 발견 과정은 이런 구조적인 문제를 결여함을 검토하며 AI의 과학이 **인간의 과학보다 더 신뢰 가능하다**는 점을 논증한다. 한편, AI의 재현 또한 인간이 수집한 데이터를 통해서 이루어지므로 인간의 과학적 연구와 동일한 재현성 위기를 가진다는 반론이 제기될 수 있다. 그러나 AI는 데이터의 정규화와 그에 대한 재보정을 통하여 데이터의 노이즈를 통계적으로 제거할 수 있으며, 학계에서 이미 자기폐쇄적 과학 연구를 수행할 수 있는 AI를 구현하는 데 성공했다는 점을 통하여 이 반론은 해소된다. 마지막으로 AI의 과학이 인간의 과학보다 더 신뢰 가능함에도 이론적 전제를 설정하고 탐구 대상에 가치를 부여하는 인간의 역할은 여전히 사라지지 않음을 살펴보고, 이 사실이 앞으로 과학계에 미칠 영향과 그 함의를 살펴본다.

## 본론

### ­검증 가능한 명제로서의 과학과 검증 가능성의 필요조건

#### 명제의 검증 가능성

어떤 명제가 과학적 명제인가? 과학과 비과학을 엄밀히 구분하려는 시도는 과학철학사가 시작된 때부터 지금까지 계속되어 왔다. 수많은 논쟁 속에서도 과학이 세계에 대한 올바른 서술을 목표하는 학문이라는 점에는 학계의 전반적인 공감이 있었기에, 카르납은 이 사실을 전제로 과학적 명제란 **검증 가능한 명제**와 동치임을 주장하였다. 그의 논증은 다음과 같다 (Carnap, 1936).

>  (a). 과학은 세계에 대한 올바른 서술을 목표하는 학문이다.
>   -> 따라서 과학은 세계에 대한 명제를 생산한다.
>
>  (b). 세계에 대한 명제가 올바른지 판단하기 위해서는 그에 대한 검증이 가능해야 한다.
>   -> 검증 불가능한 명제는 올바른지 판단할 수 없다. 
>   -> 올바른지 판단할 수 없다면 그것은 과학의 관점에서 의미 없는 명제이다. 
>   -> 따라서 검증 불가능한 명제는 과학적 명제가 아니다.
>
>   결론. 과학적 명제는 검증 가능한 명제이다. 

예컨대, 물이 두 개의 수소 원자와 한 개의 산소 원자로 이루어져있다는 명제는 과학적 명제이다. 물 분자의 원자적 구성을 확인함으로써 명제의 참·거짓 여부를 검증할 수 있기 때문이다. 그러나, 신은 존재한다는 명제는 과학적 명제가 아니다. 신이 존재하는지, 존재하지 않는지는 그 누구도 검증할 수 없기 때문이다. 신이 존재한다는 명제는 결코 의미 없다고는 할 수 없으나, 적어도 세계에 대한 올바른 서술을 목표하는 과학의 관점에서는 그 참·거짓 여부를 판단할 수 없다는 점에서 의미 없는 명제이다.

#### 검증 가능성의 필요조건으로서의 이해 가능성

어떤 명제의 검증 가능성을 판단하기 위해서는 그에 대한 **이해 가능성**이 전제되어야만 한다. 이 사실은 이해가 불가능한 명제의 참·거짓 여부의 판단 가능성을 판단할 수는 없다는 자명한 논리로부터 나온다. 예를 들어, 한 고차원적인 생물체가 그들만의 언어로 기술된 명제를 인간에게 주었다고 가정하자. 그 생물체가 참인 명제를 주었다고 하더라도, 인간은 그들의 언어를 구사할 수 없기 때문에 그 참·거짓 여부를 판단할 수 없다. 심지어는 그것이 참·거짓 여부를 판단할 수 있는 명제인지조차 판단할 수 없다. 따라서, 명제의 검증 가능성의 필요 조건은 그에 대한 이해 가능성이며, 어떤 발견이 검증을 통하여 과학으로서 정당화되기 위해서는 그 발견에 대한 이해 가능성이 전제되어야만 한다. 

### AI의 발견의 과학으로서의 정당화

#### AI의 발견에 대한 이해 가능성

AI의 추론 과정은 흔히 블랙박스(Black Box)라 일컬어지며, 이는 그 추론 과정이 마치 어두운 상자 속에서 이루어지는 것과 같아 그 내용을 알 수 없다는 점에서 붙여진 명칭이다. 현대의 AI를 작동하게 하는 알고리즘은 그 계산 과정이 너무나 복잡하고 불분명하여 인간으로 하여금 AI의 작동 원리를 분명히 파악할 수 없도록 한다. 따라서 학계에서는 AI의 블랙박스가 해소되지 않는 한 AI가 도출하는 결론들을 신뢰할 수는 없다는 주장이 제기된다. 어떻게 작동하는지조차 명확히 규명되지 못한 기계가 내놓은 결론을 학문으로서 받아들일 수는 없다는 취지의 주장이다. 그러나 추론 과정의 규명은 명제를 정립함에 있어서 필수적인 과정이 아니다. 이는 추론 과정의 블랙박스가 추론 결과의 이해 불가능성을 의미하지는 않기 때문이다. 예를 들어, 한 고차원적인 생물체가 마법을 부려서 어떤 명제를 도출해냈다고 하자. 그 명제가 그 생물체만이 이해할 수 있는 언어로 쓰여 있다면 어떤 인간도 그 내용을 이해할 수 없을 것이다. 그러나 그 명제가 '표준대기압의 물은 100도에서 끓는다.'와 같이 평범한 인간의 논리와 언어로 쓰여 있다고 해보자. 그 명제를 도출해낸 마법의 과정을 이해할 수 있는 인간은 없을 것이나, 표준대기압의 물이 100도에서 끓는다는 명제를 이해하는 것은 가능하다. 그리고 이 명제가 검증 가능한지 판단하는 것 또한 가능하다. 즉, 추론 과정의 불분명함이 그 결과의 이해 불가능성을 의미하지는 않는다. 그리고 이해 가능성이 전제된다면, 그 검증 가능성에 대한 판단 또한 가능하다. 

더하여, 추론 과정의 불분명성은 AI에게만 국한되는 문제가 아니다. 인간의 추론 과정에도 AI와 마찬가지로 블랙박스가 존재한다. 뉴턴은 떨어지는 사과를 보고 중력 이론에 대한 영감을 얻었으며, 오랜 기간 동안의 연구를 거쳐 마침내 만유인력의 법칙을 도출해내었다. 만유인력의 법칙은 뉴턴뿐만이 아닌 수많은 사람들이 이해하는 법칙이나, 정작 만유인력의 법칙을 추론해내는 과정에서 뉴턴의 뇌 속에서 어떤 작용이 일어났는지 명확히 규명할 수 있는 사람은 - 적어도 아직까지는 - 존재하지 않는다. 그러나 그와 상관없이 만유인력의 법칙은 과학 체계에 편입되었으며, 지금은 현대 물리학의 근간을 이루는 기본 원리 중 하나로서 기능한다. 즉, 인간의 발견 또한 그 추론 과정의 블랙박스에도 불구하고 추론 결과에 대한 검증을 통하여 과학적 명제로서 정당화된다. 이는 그 추론 결과가 이해 가능성을 전제하기 때문이다. 그리고 이런 정당화 과정은 이해 가능성이 전제되는 AI의 발견에도 마찬가지로 적용될 수 있다. 어두운 상자 속에서의 추론을 통하여 도출된 명제라 하더라도, 인간의 논리와 언어로 기술되었다면 이해 가능하며, 따라서 검증 가능성에 대한 판단이 가능하다. 그리고 검증 가능하다면, **그 명제는 과학적 명제로서 정당화될 수 있다.**

#### 검증 가능한 AI의 발견

그러나 앞서 언급하였듯, 이해 가능성은 검증 가능성의 **필요조건**이지, 그 **충분조건**은 아니다. 즉, 이해가 가능하며 검증이 가능한 명제가 존재하는 반면, 이해가 가능함에도 검증이 불가능한 명제가 존재한다. 그러나 학계와 산업 현장에서의 다양한 사례는 AI가 이해가 가능하며 검증 또한 가능한 명제를 생산할 수 있다는 사실을 뒷받침한다. 실제로 AI 기반 재료 탐색 파이프라인을 통하여 수백만 개의 후보 물질을 스크리닝하고, 이 과정에서 AI가 제안한 가설 일부가 학자들의 투명한 검증을 통하여 수용되었음이 재료과학 분야 학술지에 보고된 바 있다 (Merchant et al., 2023). 그리고 이러한 사례는 경험과학 분야에만 국한되지 않는다. 수학계에서는 이미 Rocq[^1] 등의 증명 지향 언어(proof oriented language)[^2]를 통한 증명의 보조가 급속히 증가하고 있으며, 증명 과정에서 AI가 제시한 명제들은 모두 투명하고 결정적인(deterministic)한 커널(kernel)을 통하여 검증된다[^3]. 다음은 AI의 증명 보조 도구로서의 활용 가능성에 대한 테렌스 타오(Terence Tao)의 전망이다.

> "I think in three years AI will become useful for mathematicians. It will be a great co-pilot (Terence Tao, 2024)."

이와 같이 AI는 이해가 가능하며 검증이 가능한 명제를 생산할 수 있다. 그리고 검증 가능한 명제는 과학적 명제로서 정당화된다. 따라서, AI는 인간과 더불어 과학적 명제를 생산하는, **과학의 주체**로서 기능한다.

### 신뢰 가능한 AI의 과학

#### 인간의 과학과 그 본질적 문제

과학적 명제란 검증 가능한 명제를 의미하며, 이 명제들 중 참으로 검증된 명제들은 기존의 과학 체계에 편입된다. AI의 시대가 도래한 지금은 인간과 AI가 함께 검증 가능한 명제의 생산을 이루어내며, 이에 따라 과학의 축적 속도는 그 어느 때보다도 빠르다. 그러나, 인간이 검증 가능한 명제를 생산하는 과정과 그 명제를 실제로 검증하는 과정은 많은 경우 신뢰도가 떨어지거나, 신뢰 가능하지 않다. 이는 인간의 과학적 연구가 본질적으로 **인지적 편향**(cognitive bias)과 **재현성 위기**(reproducibility crisis)라는 구조적 한계를 안고 있기 때문이다. 인지적 편향이란 연구자가 자신의 선입견이나 기대에 따라 데이터를 선택하거나 해석하는 경향을 말하며, 대표적으로 확인 편향(confirmation bias), 유의미한 결과만 선호하는 출판 편향(publication bias), 우연한 패턴을 의미 있는 관계로 오해하는 오귀인 편향(illusory correlation) 등이 있다. 이러한 편향들은 연구의 전반적인 과정에 스며들어 연구자가 의식하지 못하는 사이 가설 설정, 데이터 수집, 통계 분석, 결과 해석에 영향을 미치고, 이로 인해 실제보다 과장되거나 왜곡된 명제가 과학적 사실로 제시되는 경우가 적지 않다. 대표적으로, NEJM의 분석에 따르면, 미국 FDA에 제출된 항우울제(SSRI)[^4] 임상시험 중 긍정적 결과를 낸 논문은 94%가 학술지에 출판되었지만, 부정적이거나 미미한 결과를 낸 논문은 절반 이상이 미출판되었다 (Turner et al., 2008). 이는 유의미한 결과만 선호되는 출판 편향의 대표적인 예시이며, 임상 연구의 결론이 왜곡되어 마치 실제보다 약효가 높은 것처럼 과학적 사실이 잘못 제시된 사례이다. 그와 더불어 재현성 위기란 독립된 연구자가 동일한 조건으로 실험을 반복했을 때 기존의 연구 결과가 동일하게 재현되지 않는 현상을 의미한다. 심리과학 재현성 프로젝트(Open Science Collaboration)는 Science지에 발표한 대규모 재현성 실험에서, 저명 학술지에 실린 심리학 논문 100편 중 약 36%만이 통계적으로 유의하게 재현되었다고 보고하였다 (Open Science Collaboration, 2015). 의생명과학 분야에서도 유사한 결과가 발견되었는데, 암 연구 분야에서 Bayer[^5]와 Amgen[^6]이 각각 수행한 내부 재현성 검증에서는 기존에 발표된 연구의 약 20–25%만이 재현 가능한 것으로 나타났다 (Prinz et al., 2011; Begley & Ellis, 2012). 이러한 결과는 인간의 연구가 종종 견고한 검증을 통과하지 못하며, 많은 발견이 우연·편향·방법론적 오류에 의해 만들어질 수 있음을 보여준다. 따라서 인간의 과학은 상당한 비율의 편향과 재현 불가능성이라는 구조적 한계를 내포하고 있으며, 이는 **인간이 생산한 과학적 명제의 신뢰도를 근본적으로 위협한다**.

#### AI의 과학과 그 신뢰 가능성

인간의 과학이 인지적 편향과 재현성 위기라는 구조적 문제를 안고 있는 것에 비해, AI가 생산하는 과학적 명제는 이러한 인간적 한계를 본질적으로 결여한다. AI는 특정 결론을 선호하거나, 자신의 기존 신념을 유지하려는 심리적 경향을 갖지 않으며, 연구자의 경력·명성·가설에 대한 애착과 같은 비과학적 요인에 의한 영향을 받지 않는다. AI의 추론 과정은 블랙박스적 성격을 지니더라도, 그 과정에서 발생하는 계산은 일관되고 편향 없이 수행된다. 즉, 동일한 입력이 주어지면 항상 동일한 출력이 **결정적으로**(deterministically) 재현된다. 이는 인간이 의식적·무의식적 편향을 제거하기 위해 많은 노력을 들여야 함에도 불구하고 그것을 완전히 극복할 수는 없다는 점과 대비되는 특징이다. 또한 AI의 발견은 재현성의 문제에 있어서도 본질적으로 인간 연구보다 유리한 구조를 가진다. 인간 연구에서는 실험자에 따라 실험 조건이 미세하게 달라지거나 분석 방법의 선택이 다를 수 있고, 동일한 통계 기법을 사용하였다 해도 그 해석의 여지가 달라질 수 있다. 반면 AI가 산출한 명제는 동일한 데이터와 알고리즘을 사용하면 언제나 동일하게 재현되며, 정확히 같은 조건을 모사하는 것이 가능하다. 예컨대, AI 기반 재료 탐색 파이프라인이나 약물 설계 모델은 동일한 알고리즘·동일한 하이퍼파라미터·동일한 데이터셋을 주었을 때 일관된 가설을 산출하고, 그 결과는 다른 연구자가 동일한 조건으로 모델을 실행함으로써 쉽게 검증·재현할 수 있다. 이러한 구조는 인간 연구자가 실험 환경의 변화나 수집 과정의 편향을 완전히 통제하기 어려운 현실과 강력한 대조를 이룬다. 즉, AI는 인간이 피할 수 없는 편향으로부터 자유로우며, 그 발견 과정은 동일한 조건에서 결정적으로 동일한 결과를 산출할 수 있다. 따라서 AI가 이해 가능하며 검증 가능한 명제를 도출한 경우, **그 명제는 인간이 도출한 과학적 명제보다 더 신뢰 가능하다**. 이는 AI가 과학의 신뢰성을 한 단계 끌어올리는 역할을 맡을 수 있음을 의미한다.

한편, AI가 경험과학적 명제를 재현하기 위해서는 그를 위한 데이터의 입력이 필요하며, 그 데이터를 수집하는 과정은 결국 인간이 담당하기 때문에 AI 또한 연구 결과를 완전히 동일하게 재현하는 데 어려움이 따른다는 지적이 제기된다. 인간이 데이터를 수집하는 과정에서 누가 그 과정을 담당하느냐에 따라 수집 조건이 미세하게 달라질 수 있으며, 이런 데이터의 오염은 결정적인 알고리즘을 통하여 결론을 도출해내는 AI로서는 연구 결과를 재현할 수 없도록 하거나, 오히려 연구 결과를 부정하는 결론을 도출하도록 유도할 수도 있다는 것이다. 따라서 경험과학적 명제를 재현하는 데 있어서는 AI 또한 인간과 동일한 구조적 문제를 안고 있다는 취지의 주장이다. 그러나, AI는 일관적이지 못한 데이터의 질적 결함에도 그에 대한 정규화와 재보정을 통하여 **일관되고 결정적인 결론**을 도출할 수 있다. 실제로, 단백질 구조를 예측하는 AI인 AlphaFold는 인간이 수집한 X-ray·EM 구조 데이터를 기반으로 학습하지만, 그를 활용한 추론 단계에서는 실험적 잡음이나 인간의 편향을 통계적으로 제거하여 일관된 결론을 도출한다 (Jumper et al., 2021). 이는 오염된 데이터를 통한 추론은 오염된 결과를 도출한다는 기존의 인식을 완전히 뒤집고, 통계적 노이즈의 제거를 통하여 AI의 실험은 인간의 실험보다 높은 재현성을 가졌다는 점을 보인 사례이다. 더하여, 현재 학계에서 가장 활발히 연구되고 있는 월드 모델(World Model)[^7]은 구현에 성공할 시 인간의 개입 없이 데이터의 수집·분석·결론 도출을 모두 담당할 수 있을 것으로 기대된다. 이는 AI의 자기폐쇄적(closed-loop) 과학 연구 가능성을 의미하며, AI는 인간 편향의 영향이나 재현성 위기 없이 추론이 가능할 것이다. 실제로 MIT의 Self Driving Lab에서는 데이터의 수집과 재현, 그에 대한 해석을 모두 AI가 담당하여 자기폐쇄적인 연구를 수행하도록 하는 데 성공한 바 있다 (Bongard & Lipson, 2007). 이는 아직 약한 형태의 proto World Model로 평가되지만, 추후 완전한 World Model의 구현에 대한 희망적 전망을 제시한다.

더하여, AI가 위와 같이 확률적인 편향을 효과적으로 제거할 수 있을지 몰라도, 데이터 자체의 객관성이 편향되는 등 데이터 수집 단계에 내재된 구조적 편향마저 제거할 수는 없다는 반론이 제기될 수 있다. 이는 특정한 이론적 전제 하에서 특정 데이터를 수집하기로 결정하는 순간 인간의 관점이 필연적으로 개입될 수밖에 없다는 취지의 주장으로, 위의 반론과는 다른 층위에서 AI의 편향성을 지적한다. AI는 데이터 수집 단계에 내재된 구조적 편향이나 이론적 전제까지 스스로 수정할 수는 없다. 즉, 만약 입력 데이터를 선택하는 과정 자체가 편향되었다면, AI는 그에 맞추어 편향된 결론을 내놓을 수밖에 없다[^8]. 그러나, 본고에서 강조하고자 하는 AI 과학의 신뢰성은 그것이 담보하는 **과정의 무결성**에 있다. 인간은 이미 수집된 데이터를 해석하는 과정에서도 자신의 신념에 따라 결론을 왜곡하거나, 실험 때마다 다른 기준을 적용하는 수행적 편향을 범한다. 반면 AI는 비록 데이터가 편향되어 있을지라도, 주어진 데이터와 조건 안에서는 수학적으로 완벽하게 일관된 추론을 수행한다. 즉, AI는 절대적 객관성을 담보하지는 못하지만, 인간이 범할 수 있는 자의적 해석의 개입을 차단한다는 점에서 인식론적 우위를 가진다. 따라서 AI의 과학은 완전무결한 진리를 보장하기 때문이 아니라, **무결한 실험 파이프라인을 제공한다는 점에서 인간 과학의 한계를 보완할 수 있다.**


## 결론

지금까지 본고에서는 AI의 발견이 과학적 명제로서 정당화될 수 있는 논리적 근거와 인간의 과학과 대비되는 AI 과학의 신뢰 가능성에 대하여 논하였다. 과학의 본질을 세계에 대한 올바른 서술, 즉 세계에 대한 검증 가능한 명제의 생산으로 정의할 때 AI가 도출한 결과물은 비록 그 추론 과정이 불투명한 블랙박스 영역에 있을지라도 결과의 이해 가능성이 전제된다면 검증의 대상이 될 수 있다. 나아가 인간의 과학 연구가 필연적으로 내포하는 인지적 편향과 재현성 위기라는 구조적 한계와 달리, AI는 결정론적 알고리즘과 데이터 정규화, 그리고 자기폐쇄적 연구 수행 능력을 통해 일관된 결과를 산출할 수 있다. 이는 AI의 발견이 단순한 보조적 자료를 넘어, 인간의 발견보다 더 높은 수준의 신뢰성을 담보하는 과학적 명제로서 기능할 수 있음을 시사한다.

그러나 AI가 과학적 발견의 신뢰성을 제고하고 연구의 주체로서 기능한다고 하여 과학 탐구의 영역에서 인간의 역할이 사라지는 것은 아니다. 오히려 AI 시대의 도래는 인간 연구자에게 '발견의 수행자'에서 '연구의 설계자'이자 '가치의 부여자'로서의 인식론적 전환을 요구한다. AI는 주어진 목적함수 내에서 최적의 해를 찾아내고 신뢰할 수 있는 데이터를 산출하는 데 탁월하지만, 이론적 전제를 수정하면서까지 발견을 수행할 수 없다. 따라서 AI가 무엇을 탐구하도록 결정하는 것, 즉, 과학 탐구의 구조적인 편향을 조정하는 것은 여전히 인간의 몫이다. 다시 말해, 무엇이 탐구할 가치가 있는지, 도출된 명제가 인류의 지식 체계 내에서 어떠한 맥락적 의미를 갖는지를 판단하는 것은 여전히 인간의 고유한 영역으로 남는다. AI는 어떻게(How)와 무엇(What)을 검증하는 데 있어 인간을 능가할 수 있으나, **왜(Why)에 대한 근원적 물음과 연구의 방향성을 설정하는 주체성은 인간에게 귀속된다.**

결국 이러한 AI의 등장은 인간 과학의 종말이 아닌, 그 확장을 의미한다. AI가 제공하는 무결점의 재현성과 신뢰성은 인간의 직관이 닿지 못했던 미지의 영역으로의 탐구를 가능하게 할 것이며, 인간은 더 높은 차원의 이론적 통합과 철학적 해석을 시도하게 될 것이다. 따라서 미래의 과학은 인간과 AI의 대립적 구도가 아닌, 신뢰 가능한 연산 능력과 창의적 의미 부여가 결합된 상호보완적 형태를 띨 것이다. 이것이 인간이 신뢰 가능한 AI의 과학을 두려움이 아닌 기대로 맞이해야 하는 이유이며, 바로 이 지점에서 과학은 비로소 인간의 생물학적 한계를 넘어 진정한 의미의 보편적 지식 탐구로 나아가게 될 것이다.


[^1]: Rocq: 프랑스 국립 컴퓨터 과학 및 자동화 연구소(INRIA) 주도로 개발된 상호작용형 정리 증명기이자 형식 언어. 구성적 논리(Calculus of Inductive Constructions)를 기반으로 하여 수학적 정의와 증명 과정을 코드로 기술하면, 컴퓨터 커널(kernel)이 그 논리적 정합성을 엄밀하게 검증한다. 최근에는 AI가 생성한 수학적 증명이 오류가 없음을 보증하는 최종 검증 플랫폼으로 활발히 활용되고 있다.

[^2]: Proof Oriented Language(증명 지향 언어): 일반적인 프로그래밍 언어(C, Python 등)가 소프트웨어 개발이나 연산을 목적으로 하는 것과 달리, 수학적 정리와 그 증명을 형식적으로 기술하고 검증하기 위해 설계된 특수 언어를 말한다. 이 언어를 사용하면 모호할 수 있는 자연어 대신 엄밀한 코드로 논리를 전개할 수 있으며, 컴퓨터가 이를 해석하여 논리적 비약이나 오류가 없는지 즉각적으로 판별해 준다. 대표적인 예로 Rocq, Lean, Isabelle 등이 있다.

[^3]: 결정적 커널(Deterministic Kernel): 커널(Kernel)이란 소프트웨어의 가장 핵심이 되는 부분으로, 여기서는 명제의 최종 검증기 역할을 한다. 결정적(Deterministic)이라는 것은 이 검증기가 언제나 똑같은 입력에 대해 똑같은 판정을 내린다는 뜻이다. 즉, 결정적인 커널은 수학적 논리에 따라 예외 없이 엄격하고 일관되게 오류 여부를 판별한다.

[^4]: SSRI(Selective Serotonin Reuptake Inhibitor, 선택적 세로토닌 재흡수 억제제): 현대 정신의학에서 우울증 및 불안 장애 치료에 가장 널리 처방되는 대표적인 항우울제 약물군이다.

[^5]: Bayer(바이엘): 독일 레버쿠젠에 본사를 둔 세계적인 다국적 제약 및 생명과학 기업. 아스피린의 개발사로 대중에게 잘 알려져 있다.

[^6]: Amgen(암젠): 미국 캘리포니아에 본사를 둔 세계 최대 규모의 생명공학 기업. 전통적인 합성 의약품이 아닌 생물학적 제제 분야를 선도하고 있다.

[^7]: 월드 모델(World Model): AI가 외부 세계의 환경과 상호작용하며 그 작동 원리(물리 법칙, 인과 관계 등)를 스스로 학습하여 구축한 내부 시뮬레이션 모델을 말한다. 월드 모델을 갖춘 AI는 실제 실험을 수행하기 전에 가상의 시뮬레이션을 통해 결과를 예측하고 계획을 수립할 수 있다.

[^8]: Garbage In, Garbage Out(GIGO): 컴퓨터 과학 및 정보 처리 분야의 널리 알려진 격언으로, '쓰레기가 들어가면 쓰레기가 나온다'는 의미이다. 이는 시스템의 처리 로직이 아무리 완벽하더라도 입력되는 데이터(Input)의 품질이 나쁘면 산출되는 결과(Output) 역시 무의미하거나 오류를 포함할 수밖에 없다는 원칙을 나타낸다.



## 참고 문헌

### 해외 문헌

> Carnap, R. (1936). Testability and meaning. Philosophy of Science, 3(4), 419–471.
>
> Merchant, A., Batzner, S., Schoenholz, S. S., Aykol, M., Cheon, G., & Cubuk, E. D. (2023). Scaling deep learning for materials discovery. Nature, 624(7990), 80-85. 
>
> Open Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), aac4716.
> 
> Prinz, F., Schlange, T., & Asadullah, K. (2011). Believe it or not: how much can we rely on published data on potential drug targets? Nature Reviews Drug Discovery, 10(9), 712.
> 
> Begley, C. G., & Ellis, L. M. (2012). Drug development: Raise standards for preclinical cancer research. Nature, 483(7391), 531–533.
>
> Bongard, J., & Lipson, H. (2007). Automated scientific discovery by an autonomous robot. Nature, 449(7164), 727–731.
>
> Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., ... & Hassabis, D. (2021). Highly accurate protein structure prediction with AlphaFold. Nature, 596(7873), 583-589.
> 
> Wong, M. (2024, March 5). Math’s ‘Mozart’ is using AI to solve the unsolvable. The Atlantic.




