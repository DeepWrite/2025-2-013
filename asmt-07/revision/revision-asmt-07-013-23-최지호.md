---
title: (개선) 과제-07 개인별 논증 구조 작성하기 013-23 최지호
layout: home
nav_order: 99
parent: 013-23 최지호 (과제-07)
permalink: /asmt-07/013-23/revision
---

# (개선) 과제-07 개인별 논증 구조 작성하기 013-23 최지호 

## 개선 사항 메모

전제 2, 전제 3에서 형식과학에 대한 예시 외에 경험과학에 대한 예시를 추가하였다.
재반박에서 생략되었던 전제를 명시하였고, 그에 대한 논증을 보다 구체적으로 덧붙여 설득력을 강화하였다.

## 제목: 과학적 발견에의 인공지능 활용 가능성  

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | 과학적 발견에의 인공지능 활용 가능성 |
| 도전하려는 쟁점 | 인공지능이 생성한/인공지능을 활용한 과학적 발견을 '과학'이라고 할 수 있는가 |
| 딜레마/난제 | 과학으로 보기에는 블랙박스 존재 / 과학으로 보지 않기에는 인간에게도 부분적 블랙박스 존재 |
| 딜레마/난제 해소/해결 방법 | 추론 생성 과정에서의 블랙박스가 추론의 이해 불가능성을 의미하지는 않는다. |

① 주제(Topic): 과학적 발견에의 인공지능의 활용 가능성

② 도전하는 학술적 쟁점: 인공지능이 생성한/인공지능을 활용한 과학적 발견을 '과학'이라 할 수 있는가?

- **과학은 추론 과정의 이해 가능성을 전제해야 하는가?**  
- **인공지능의 블랙박스는 과학의 전제를 위반하는가?**  
- **인공지능의 과학적 발견은 신뢰 가능한가?**

③ 유발되는 딜레마 또는 난제

- 딜레마 구조
  - **(A)** 인공지능의 블랙박스는 인간이 이해 불가능한 과학적 발견을 이루어낼 수도 있다. 그것을 여전히 과학이라 할 수 있는가? 
  - **(B)** 그러나 인간의 추론 과정에도 부분적으로 블랙박스가 존재한다. 인공지능의 블랙박스와 인간의 블랙박스를 달리 볼 근거는 무엇인가?

④ 딜레마 해소 (또는 난제 해결) 전략

- 과학은 본질적으로 검증 가능해야 하며, 이를 위해서는 이론의 이해 가능성이 전제되어야 한다.
- 추론 과정의 블랙박스가 그 결과의 이해 불가능성을 의미하지는 않는다.
- 이해 가능한 추론 결과라면 그 검증 과정을 인간이 담당할 수 있으며, 이해 불가능한 추론 결과라면 그 판단을 유보함으로써 과학으로의 편입을 제한할 수 있다.
- 따라서 **인공지능의 과학적 발견**은 추론 생성 과정의 블랙박스에도 불구하고 그 검증 과정을 통하여 **과학**으로서 정당화될 수 있다.

## 2. 논증구조

### 기본구조

- **논제:** 인공지능의 과학적 발견은 과학으로서 정당화될 수 있다.
  - **전제1:** 과학은 본질적으로 검증 가능해야 하며, 따라서 이해 가능해야 한다.
    - 어떤 명제가 과학적 의미를 가지려면, 그것을 검증하거나 반박할 수 있어야만 한다. (Carnap, 1936, p. 420.)
	 - 이해할 수 없는 명제를 검증하거나 반박하는 것은 불가능하다. 
  - **전제2:** 인공지능의 추론 과정의 블랙박스가 추론 결과의 이해 불가능성을 의미하지는 않는다.
    - 인공지능이 추론을 생성하는 과정을 이해할 수는 없지만, 그 과정을 통하여 생성되는 형식 언어로서의 결과는 인간이 이해할 수 있다.
    - 실제로, 수학적 증명을 자동화하는 RCoQ 등의 proof-oriented language가 수학적 증명을 생성하는 과정은 인간이 이해할 수 없으나, 도출된 수학적 증명은 형식 언어를 따르며, 인간이 이해할 수 있다.
    - 경험 과학적 명제 또한 추론 생성 과정에 대한 이해 없이도 형식 언어로 기술되었다면 인간이 이해 가능하다. 예시로, 재료과학 분야에서 LLM이 실험 가능하고 검증 가능한 가설을 제안했음이 보고된 바 있다. (Chen et al., 2024, p. 4)
  - **전제3:** 이해 가능한 추론 결과라면 그 검증 과정을 인간이 담당할 수 있으며, 이해 불가능한 추론 결과라면 그 판단을 유보함으로써 과학으로의 편입을 제한할 수 있다.
    - RCoQ 등을 통하여 자동으로 생성된 수학적 증명은 투명하고 결정적인(deterministic)한 커널(kernel)을 통하여 검증되며, 이 과정은 인간이 완전히 이해 가능하다. 따라서 인간이 인공지능의 발견을 검증하거나 반박할 수 있으며, 신뢰 가능성 또한 판단할 수 있다. 즉, 그 참∙거짓 여부에 따라 해당 명제를 과학적 지식으로 편입할 수 있다.
    - 실제로 AI가 제안한 재료과학 분야의 가설은 연구자들의 투명한 검증을 통하여 부분적으로 수용되었다. (Chen et al., 2024, p. 4)
    - 인공지능의 추론 결과가 인간이 이해할 수 없는 명제라면, 그것은 인간에 의하여 검증되거나 반박될 수 없다. 따라서 그것을 과학적 발견으로 보는 것은 부적절하다.
- **결론:** 따라서, 인공지능의 블랙박스에도 불구하고, 인공지능이 생성한/인공지능을 활용한 과학적 발견은 과학으로서 정당화될 수 있다.

### 예상반론과 재반박

- **예상반론(연역적 논증의 타당성 공격):** **전제1**에서 '검증 가능성'은 과학의 충분조건이 아닌 필요조건이며, 과학적 방법론을 따라서 추론 과정이 전개되었는지 또한 고려해야 인공지능의 발견을 과학이라 할 수 있는지 여부를 판단할 수 있다.
  - 논리적 취약점 지적: 인공지능의 과학적 발견이 과학의 필요조건에 해당될 수 있다는 것만으로는 그것이 과학으로 정당화될 수 있다는 명제가 성립하지 않는다. 

- **재반박:** 추론 과정의 방법론은 과학의 충분조건에도 필요조건에도 해당하지 않으나, 그 검증 가능성은 과학의 필요충분조건이다.
 - **소전제1:** '과학적 방법론'은 참으로 검증되는 이론을 생산하는 경우가 가장 많았던 방법론이 자연선택된 결과이며, 과학의 본질과 인과적 관계를 가지지 않는다.
  - 가설 설정과 실험을 통한 검증과 같은 현대의 과학적 방법론은 17세기의 과학 혁명 이후에나 정립되었고, 이전에도 성서로부터의 연역, 순수 이성을 통한 연역적 추론 등 수많은 방법론들이 '과학적 방법론'을 대표하였다.
  - 그 중 실험 - 검증을 통한 방법론이 현대까지 존속하는 이유는 그 정확도가 가장 높았기 때문이며, 이는 과학적 방법론의 정립이 자연선택적 과정을 통하여 이루어졌음을 의미한다.
 - **소전제2:** 검증 가능성은 과학의 필요충분조건이다.
  - 어떤 명제가 의미를 가지려면 그것은 경험적으로 참·거짓을 판별할 수 있어야 하며, 그 역도 성립한다. (Carnap 1936, 420; Schlick 1932, 98)
  - 과학은 의미 있는 명제들의 체계이며, 따라서 과학은 검증 가능한 명제들의 체계이다. (Carnap 1934, §2; Ayer 1936, 47)


## 참고문헌

- Carnap, Rudolf. “Testability and Meaning.” Philosophy of Science 3, no. 4 (October 1936): 419–471; 4, no. 1 (January 1937): 1–40.
- Carnap, Rudolf. 1936. Philosophy and Logical Syntax. London: Kegan Paul, Trench, Trubner & Co.
- Chen, Chen, Ayman Maqsood, Zhuang Zhang, Xiaobing Wang, Linrui Duan, Huanhuan Wang, Tianyang Chen, Siyu Liu, Qiutong Li, Jingshan Luo, and T. Jesper Jacobsson. 2024. “The Use of ChatGPT to Generate Experimentally Testable Hypotheses for Improving the Surface Passivation of Perovskite Solar Cells.” Cell Reports Physical Science 5 (7): 102058. https://doi.org/10.1016/j.xcrp.2024.102058.
- Schlick, Moritz. 1932. “Positivism and Realism.” Erkenntnis 3 (1): 1–31.
- Ayer, A. J. 1936. Language, Truth and Logic. London: Victor Gollancz.

