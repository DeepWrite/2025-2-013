---
title: (개선) 과제-07 개인별 논증 구조 작성하기 013-22 장종윤
layout: home
nav_order: 99
parent: 013-22 장종윤 (과제-07)
permalink: /asmt-07/013-22/revision
---

# (개선) 과제-07 개인별 논증 구조 작성하기 013-22 장종윤 

## 개선 사항 메모

1. 논증 구조 변경에 따른 딜레마 해소 전략 명료화
2. 논증 구조에서 전체 논증을 AI와 인간 과학자의 유비로 대체
3. 전제1 조정 및 기존 전제 2와 전제 3의 통합, 새 전제 3 제시
4. 숨은 전제들 명시화
5. 예상반론과 재반론 변경

6. 쟁점과 딜레마 구체화
7. 전제 0 재구조화(논의하는 과학 지식 생산 과정과 과학 지식의 구분, 논의되는 과학의 범위 제한)
8. 

## 제목: AI의 설명 불가능성과 과학적 합리성: 기능적 대체 가능성 논증

## 1. 쟁점과 딜레마

| 구분 | 내용 |
|:---|:---|
| 주제(Topic) | AI의 내부 작동 원리를 이해하지 못하는 상태에서, AI가 생성한 결과를 어느 수준까지 과학적 지식으로 승인할 수 있는가. |
| 도전하는 쟁점 | 블랙박스성에도 불구하고 AI 산출을 과학 지식으로 임시 수용할 수 있는 최소 요건은 무엇인가. |
| 딜레마/난제 | 설명적 합리성을 우선하면 탐색과 발견의 기회를 상실할 수 있으며, 기능적 합리성을 우선하면 설명성과 책임성이 약화될 위험이 커진다. |
| 딜레마/난제 해소/해결 방법 | 지식의 생산 과정에 있어 AI는 인간 과학자와 산출물, 연구 핵심 원리, 연구 지침에서 상응하는 능력을 가질 수 있다. |

① 주제(Topic): AI의 내부 작동 원리를 이해하지 못하는 상태에서, AI가 생성한 결과를 어느 수준까지 과학적 지식으로 승인할 수 있는가.

② 도전하는 학술적 쟁점: 블랙박스성에도 불구하고 AI 산출을 과학 지식으로 임시 수용할 수 있는 최소 요건은 무엇인가.

③ 유발되는 딜레마 또는 난제
- 딜레마 구조 (설명적 합리성 vs. 기능적 합리성의 충돌) 
    - **(A)** 설명적 합리성의 요구: AI의 작동 원리를 이해할 수 없다면, 그 산출을 수용하는 것은 맹목적 신뢰가 될 위험이 있다. 오류 발생 시 책임과 원인 규명이 어렵고, 과학적 합리성의 핵심인 정당화 가능성이 훼손될 수 있다.
    - **(B)** 기능적 합리성의 요구: AI는 인간이 접근할 수 없는 탐색 공간에서 새로운 관찰 명제, 예측, 실험 설계를 산출할 수 있다. 설명적 한계 때문에 이 산출을 배제하면, 과학의 핵심 가치인 발견, 탐색, 문제 해결력의 향상을 스스로 제한하게 된다.

    - 예를 들어, 한 연구실에서 새로운 연소 재료의 특성을 조사하고자 할 때, AI 시스템은 이전에 수행된 다수의 소규모 시험 데이터를 바탕으로 기존 이론과는 다소 어긋나는 실험 조건(온도, 압력, 혼합 비율)을 제안한다. 이 조건은 통계적으로는 높은 성공률을 보였지만, 왜 그런 결과가 나오는지에 대한 이론적 설명은 부족하다. 반면 인간 연구자는 열역학, 유체역학의 정립된 이론들과 잘 정합되는 보수적인 조건을 제안하지만, 해당 재료 조합에 대해서는 실제 실험 경험이 없다. 예산, 시간 제약으로 당장은 한 번만 실험할 수 있을 때, 어느 쪽 설계를 선택할 것인가?

④ 딜레마 해소 (또는 난제 해결) 전략
    - 과학적 지식을 승인하는 과정은 1차 과정(생산)과 2차 과정(책임, 정당화)로 구분되어야 한다.
    - 1차 과정에서는 ‘설명’이 아니라 결과, 과정, 연구 활동의 기능적 기여를 평가 기준으로 삼아야 한다.
    - AI는 다음의 세 층위에서 인간 과학자와 기능적으로 상응한다.
        - 관찰 명제의 산출은 행위자 중립적 기준(진리성, 반증 가능성, 재현성)으로 평가된다.
        - 산출 과정은 인간 암묵지와 동일하게 조작 가능성, 오류 수정 능력으로 판단된다.
        - 연구 활동 전체는 문제 해결력 증가를 기준으로 이론 진보 여부가 판정되며, AI는 이 진보에 기여할 수 있다.

    - 결론: 문제는 ‘설명 부족’이 아니라 ‘기능적 상응성’의 존재 여부이다. 1차 지식 생산의 범위 안에서는, 설명 불가능성을 이유로 AI 산출을 전면적으로 배제할 근거는 약하며, 과학적 지식의 생산자로 제한적 승인할 수 있다.

## 2. 논증구조

### 기본구조

- **논제:** AI는 비이해적 구조에도 불구하고, 과학적 지식 생산의 1차 과정에서 요구되는 핵심 기능의 일부를 일정한 조건과 범위 안에서 인간 과학자와 유사한 수준으로 수행할 수 있다. 이때 AI의 산출은 행위자 중립적 판정 기준을 충족하는 한에서 조건부로 과학적 지식으로 승인될 수 있다.

- **전제0:** 과학적 지식 생산은 1차 과정과 2차 과정을 나누어 분석할 수 있고, 1차 과정은 실험 결과, 실험 과정, 연구 과정의 층위로 구분된다.

  - 소전제 0-1: 분석의 편의를 위해 지식 생산을 1차 과정(발견, 관찰 명제 산출, 초기 검증)과 2차 과정(책임 배분, 윤리 판단, 정책, 규제 정당화)으로 구분한다. 
    - 1차 과정에서는 성능, 재현, 통제와 같은 행위자 중립적 기준이 중심이 되며, 2차 과정에서는 책임 귀속, 위험 관리, 제도 설계와 같은 규범적, 정치적 기준이 전면에 등장한다. 이 둘은 상호 영향을 주고받지만, 2차 과정에서의 어려움이 곧바로 AI의 1차 기여를 전면적으로 금지해야 한다는 결론을 요구하지는 않는다. 
    - 즉, 1차 과정의 합리성 기준이 2차 과정의 기준과 완전히 동일할 필요는 없으며, 1차 과정에 대한 분석만으로도 AI가 지식 생산자로서 인간 과학자와 기능적으로 상응하는가라는 질문에 의미 있는 답을 줄 수 있다는 것이다. 반대로, 의료, 원자력, 군사 등 고위험 영역에서는 2차 규범이 1차 승인 기준을 강하게 제약할 수 있으며, 이 경우 본 논의의 적용 범위에서 예외로 다뤄질 수 있다. 

  - 소전제 0-2: 실험 단위
    - 실험은 장비, 환경, 조작을 통해 세계에 개입하고 그 반응을 관찰 명제로 산출하는 단위 행위이다.
    - 관찰 명제는 과학적 지식의 최소 단위이다.

  - 소전제 0-3: 산출 과정
    - 동일 과업을 지속적, 안정적으로 수행하기 위해 필요한 조정, 교정, 숙련의 체계를 포함한다.
    - 이 층위는 인간에게서는 암묵지, AI에게서는 형식 체계, 학습, 최적화 과정이 담당한다. (Polanyi, 1966/2009; Lu, 2025)
    - 이때, AI의 형식 체계가 복잡도와 관계없이 일관성을 가진다고 상정한다. 

  - 소전제 0-4: 연구 활동
    - 여러 실험의 집합이 연구 프로그램을 형성하며, 이론은 진보하거나 퇴행한다.
    - 라카토시에 따르면 이론의 진보는 문제 해결력의 증가로 정의된다. (Lakatos, 1978)

  - 소전제 0-5: 단일한 과학철학 교리를 전개하기보다는, 특정 쟁점에 초점을 맞추어, 여러 이론으로부터 겹치는 핵심 요소를 도구적으로 차용한다.
    -  포퍼의 반증 가능성 개념, 라카토시의 연구 프로그램 이론, 라우던의 문제 해결력 중심 진보 관점은 모두 과학 이론과 연구 활동의 합리성을 문제 해결, 예측, 반증 가능성의 기준으로 평가한다는 공통 핵심을 지닌다.
    -  폴라니와 해킹의 논의는 여기에 실험과 숙련, 조작 가능성에 대한 실천적 관점을 보완한다.  
 
  - 소전제 0-6: 과학의 범위
    - 과학은 물리학, 화학, 생물학, 지구과학, 공학 및 이들과 유사한 방식으로 운영되는 경험적, 실험적 연구 전통을 가리킨다. 
      - 실험 장비와 측정 기기를 사용해 세계에 개입하고
      - 그 결과를 관찰 명제의 형태로 기록하며 
      - 이러한 명제의 지위를 반증 가능성, 재현성, 문제 해결력 등을 기준으로 판정하는 영역이다.
    - 해석학적 인문학, 규범 이론, 순수 수학 등처럼 관찰 명제, 실험을 중심으로 하지 않는 분야는 이 글의 논의 범위에서 제외한다. 이하에서 말하는 과학적 합리성은 이러한 경험적, 실험적 과학에서의 1차 지식 생산 과정을 전제로 한다.

  - 소결론: 따라서 AI가 이 세 층위 각각에서 인간과 기능적으로 상응한다면, 비이해적 산출이라도 과학적 지식 생산의 일부로 승인 가능하다.

- **전제1:** 관찰 명제의 수용은 행위자 중립적으로 이루어지며, AI와 인간은 결과 수준의 상응성이 성립한다. 
  - 소전제 1-0: 관찰 명제는 진리값, 정당화 가능성, 기존 이론과의 정합성을 기준으로 분류 된다. 
        * K1: 경험적으로 참이 정당되고 기존 이론과 정합적인 지식.
        * K2: 경험적으로 참이 정당되나 기존 이론과의 정합성이 불명하며 현재는 이해되지 않는 지식.
        * K3: 진리값과 정당화 가능성이 불명인 명제.
        * K4: 경험적으로 반증된 거짓 명제.

  - 소전제 1‑1: 관찰 명제의 인식론적 지위는 행위자 독립적이다. 
    - 포퍼, 라카토시적 전통에 따르면, 관찰 명제의 판정 기준은 다음 네 가지이다. (Popper, 1959/2002; Lakatos, 1978)
        - 경험적 진리성 또는 근사 진리성
        - 반증 가능성
        - 독립 재현성 
        - 기존 이론과의 관계
    - 이 기준은 인간의 이유 제시 능력과 무관하다.

  - 소전제 1‑2: K2 명제의 처리 기준은 인간과 AI 모두에게 동일하게 적용된다
    - K1~K4 구분은 경험적 지지와 이론적 정합성의 조합을 모형적으로 분류하기 위한 분석 틀이다.  
    - 이 모형에서 K2 명제는 이론 혁신의 초기 신호를 포착하는 데 유용하다.  
    - AI가 산출한 K2 명제가 동일한 절차를 통과한다면, 인간의 K2 명제와 동일한 인식론적 지위를 갖는다.

  - 소전제 1‑3: 이유 제시의 부재는 관찰 명제의 1차 판정을 부정하지 않는다
    - 이유 제시는 이론의 층위에 속한다.
    - 관찰 명제의 1차 승인 기준은 설명이 아니라 세계와의 부합, 재현성이다.
    - 실천적으로 AI 산출물에 행위자 중립적 규범을 적용하려면, 추가적으로 제도적 장치가 필요하지만, 이 장치들이 충족된 경우에는 인간과 AI 모두 동일한 기준으로 평가할 수 있다.

  - 소결론: 관찰 명제의 수준에서는 AI가 인간과 동일한 판정 규범 아래 놓이며, 결과 수준의 상응성이 성립한다.

- **전제2:** 조작 가능성과 오류 수정 능력에 따라 AI의 내부 형식 체계는 암묵지와 기능적으로 상응한다. 
  - 소전제 2‑1: 실험, 숙련, 암묵지의 본질은 ‘조작 가능성’이다
    - 실험 행위는 설명이 아니라 세계에 성공적으로 개입하는 능력에 의해 규정된다.
    - 인간의 암묵지 역시 “어떤 조정, 조작이 성공을 낳는가”에 관한 체화된 규칙들의 체계이다. (Polanyi, 1966/2009; Malik, 2023)

  - 소전제 2‑2: AI의 내부 형식 체계는 조작 가능성을 수행한다
    - AI가 다음 조건을 충족할 때 인간의 암묵지와 기능적으로 상응한다.
      - 절차 역량성: 동일 조건에서 안정적 결과 산출
      - 오류 수정: 피드백을 기반으로 성능 개선
      - 맥락 민감성: 환경, 장비, 분포 변화에 대한 적응
      - 규범 준수성: 제약, 조건 적용 시 성능 향상
      - 전이 가능성: 유사 과업에서의 성능 유지
    - 이러한 목록은 귀납적 일반화에 의한 사실이 아니라 규범적 정의이다. 

  - 소전제 2‑3: AI의 불투명성은 조작 가능성을 부정하지 않는다
    - 설명 부재는 조작 능력의 결여를 의미하지 않는다. 
    - 인간의 암묵지 또한 대부분 비서술적이며 불투명하다. (Polanyi, 1966/2009)
    - 암묵지가 장기적으로 형식화될 수 있다는 가능성은 2차 정당화의 문제이며, 1차 지식 생산 단계에서의 승인 여부는 현재의 성능, 재현, 통제에 의해 판정된다.

  - 소결론: AI는 이유 제시 없이도 조작 가능성과 오류 수정 능력을 통해 산출 과정 수준에서 인간 실험자의 암묵지와 기능적으로 상응할 수 있다.

- **전제3:** 라카토시의 연구 프로그램의 기준에 따라 AI의 연구 활동은 인간의 활동에 상응한다. 
  - 소전제 3‑1: 연구 프로그램의 진보는 설명이 아니라 문제 해결력의 증가이다
    - 라카토시: 진보는 “새로운 예측, 현상 포착, 변칙 사례 해소” 등 문제 해결력의 순증이다. (Lakatos, 1978)
    - 설명은 진보의 결과이지, 진보의 조건이 아니다. (Laudan, 1977)

  - 소전제 3‑2: AI는 연구 프로그램의 문제 해결력을 실질적으로 증가시킬 수 있다. (King et al., 2009)
    - 사람이 탐색하지 못한 공간에서 새로운 예측 생성
    - 변칙 사례에 대한 실험 설계 제안 (Jumper et al., 2021; Szymanski et al., 2023)
    - 자원 대비 효율이 높은 문제 해결
    - 기존 보호대의 조정 또는 확장에 기여

  - 소전제 3‑3: AI의 비이해성은 연구 활동의 기여를 무효화하지 않는다
    - 진보 판정은 이해가 아니라 예측, 문제 해결, 재현, 통합 능력에 기초한다.
    - AI의 산출은 이론화의 출발점을 제공할 수 있다.

  - 소전제 3-4: 연구 프로그램의 진보는 먼저 문제 해결력의 증가라는 기능적 지표로 포착되며, 설명적 정교화와 메커니즘 이해는 그 뒤를 잇는 이차적, 후행적 단계로 나타난다. 이때 후행 단계에서의 설명 실패는 1차 단계에서의 기능적 성과를 소급 부정하는 것이 아니라, 해당 성과의 적용 범위와 제도적 지위를 조정하는 기준으로 작동한다.

  - 소결론: 연구 활동 전체 차원에서도 AI는 이론의 진보를 견인하는 행위자로 기능할 수 있다.

- **결론:** 각각 결과, 과정, 연구 활동의 세 층위에서, 일정한 조건과 범위 안에서 AI와 인간 과학자의 상응 가능성이 존재한다. 이때 상응성은 “AI가 인간 과학자와 전면적으로 동등한 합리성을 가진다”는 강한 주장이 아니라,  
    > 경험적, 실험적 과학의 1차 지식 생산 과정에서 요구되는  
    > 행위자 중립적 판정 규범, 조작 가능성, 문제 해결력이라는 기준을,  
    > AI가 적어도 일부 영역에서 일정 범위와 조건 안에서 충족할 수 있으면,  
    > 그 경우 AI 산출을 과학적 지식 생산의 한 요소로 조건부 승인하는 것이 가능하다

### 예상반론과 재반박: 암묵지의 형식화 가능성 반론에 대한 대응

- **예상반론(유비의 취약점 공격):** 인간의 암묵지가 본질적으로 비명제적, 비서술적인 것이 아니라, 단지 아직 충분히 형식화되지 않았을 뿐인 잠정적 규칙들의 집합이라는 점에 있다. 즉, 암묵지는 본질적 특성 때문에 불투명한 것이 아니라, 시간이 부족하거나 비용이 크거나 형식화의 우선순위가 낮기 때문에 명시적 규칙으로 정리되지 않았을 뿐이라는 것이다. 이러한 견해에 따르면 실험실에서의 관행과 숙련 규칙들은 대부분 매뉴얼, 체크리스트, 표준 운영 절차, 품질 규격의 형태로 이전 가능한 것들이며 재현성 향상 또한 표준화와 교정 절차, 통계적 관리 기법의 확산으로 설명할 수 있다. 더 나아가 많은 전문가의 판단과 의사결정 휴리스틱은 통계 모델이나 제어 이론, 혹은 규칙 기반 체계로 번역 가능하므로, 암묵지를 인간 고유의 비명제적 기술로 이해할 이유는 없다. 신체화가 강하게 요구되는 소수의 기술을 제외하면, 대다수의 숙련은 관찰과 기록, 비교 작업을 통해 결국 규칙으로 환원될 수 있다. 이러한 전제에서 보면, 인간의 암묵지와 AI 내부 알고리즘 사이의 유비는 본질적이라기보다는 과장되었으며, 기능적 상응성도 그만큼 약해진다.

- **재반박:** 이러한 반론은 장기적인 형식화 가능성과 현재의 승인 기준, 즉 지식 생산의 1차 과정이 요구하는 판단 기준을 혼동하고 있다. 발견, 관찰 명제 산출, 초기 검증으로 이루어진 1차 과정의 승인 판단은 규칙의 서술 가능성보다 지금 이 순간의 성능, 재현성, 통제 가능성에 달려 있다. 암묵지가 장기적으로 형식화될 수 있다는 가능성은 2차 정당화의 영역에 속하며, 1차 산출의 승인 여부와는 다른 차원의 문제다. 오히려 형식화가 완성될 때까지 AI의 탐색, 발견 기능을 배제하는 것은 과학 발전에서 중요한 기회를 상실하는 결과를 낳을 수 있다. 충분한 성능과 재현성과 통제가 확보된 경우에는, 이것이 인간이든 AI든 간에 해당 산출을 제한적, 임시적으로 승인하는 것이 실질적으로 더 합리적이다.

## 참고문헌

- Hansson, S. O. (2025). Science and pseudo-science. In E. N. Zalta & U. Nodelman (Eds.), The Stanford Encyclopedia of Philosophy (Summer 2025 ed.). Metaphysics Research Lab, Stanford University. https://plato.stanford.edu/archives/sum2025/entries/pseudo-science/  
- Popper, K. (1959/2002). The Logic of Scientific Discovery.

- Polanyi, M. (1966/2009). The Tacit Dimension. “We can know more than we can tell”
- Malik, A. (2023). Tacit knowing: What it is and why it matters. Episteme, 20(2), 349–366. https://doi.org/10.1017/epi.2021.41
- Lu, J. (2025). Tacit knowledge in large language models (GMU Working Paper in Economics No. 25-25). SSRN. https://doi.org/10.2139/ssrn.5320627
- Munafò et al. (2017). “A Manifesto for Reproducible Science.”

- Lakatos, I. (1978). The Methodology of Scientific Research Programmes.
- Laudan, L. (1977). Progress and Its Problems.
- King, R. D., et al. (2009). “The Automation of Science.”
- Jumper, J., et al. (2021). “Highly accurate protein structure prediction with AlphaFold.”
- Szymanski, N. J., et al. 2023. An autonomous laboratory for the accelerated synthesis of novel materials. Nature 624, 86–91.